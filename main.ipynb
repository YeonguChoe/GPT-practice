{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "126786a8",
   "metadata": {},
   "source": [
    "# GPT Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c6ae4ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/yeonguchoe/Library/Python/3.9/lib/python/site-packages (2.8.0)\n",
      "Requirement already satisfied: fsspec in /Users/yeonguchoe/Library/Python/3.9/lib/python/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/yeonguchoe/Library/Python/3.9/lib/python/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in /Users/yeonguchoe/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: filelock in /Users/yeonguchoe/Library/Python/3.9/lib/python/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: jinja2 in /Users/yeonguchoe/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/yeonguchoe/Library/Python/3.9/lib/python/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/yeonguchoe/Library/Python/3.9/lib/python/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yeonguchoe/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e112b592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Open data\n",
    "f = open(\"input.txt\", \"r\", encoding=\"utf-8\")\n",
    "text = f.read()\n",
    "print(type(text))\n",
    "text_length = len(text)\n",
    "half_text_length = len(text) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1e5dee9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique characters\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "379964ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary\n",
    "char_to_int = {element: index for index, element in enumerate(chars)}\n",
    "int_to_char = {index: element for index, element in enumerate(chars)}\n",
    "\n",
    "\n",
    "# Encode str into int list\n",
    "def encode(s):\n",
    "    result = []\n",
    "    for character in s:\n",
    "        result.append(char_to_int[character])\n",
    "    return result\n",
    "\n",
    "\n",
    "# Decode int list into str\n",
    "def decode(tensor):\n",
    "    l = tensor.tolist()\n",
    "    converted = []\n",
    "    for int in l:\n",
    "        converted.append(int_to_char[int])\n",
    "    result = \"\".join(converted)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1f29e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor\n",
    "import torch\n",
    "\n",
    "data = torch.tensor(data=encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "57ab6da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KPop Demon Hunters is a 2025 American animated musical urban fantasy film. It was directed by Maggie Kang and Chris Appelhans, who also co-wrote the screenplay with Danya Jimenez and Hannah McMechan.\\nThe story was originally created by Kang.\\nThe film was produced by Sony Pictures Animation for Netflix.\\nThe film features the voices of Arden Cho, Ahn Hyo-seop, May Hong, Ji-young Yoo, Yunjin Kim, Daniel Dae Kim, Ken Jeong, and Lee Byung-hun.\\nIt tells the story of a K-pop girl group called Huntr/x,[a] who secretly work as demon hunters.\\nThey face off against a rival boy band, the Saja Boys, whose members are secretly demons.\\nKang was inspired to create the story by her Korean heritage. She combined elements of mythology, demon stories, and K-pop to make a film that is both visually unique and culturally meaningful.\\nBy March 2021, the project was officially in production at Sony Pictures Animation, with the full creative team on board.\\nThe animation was done by Sony Pictures Imageworks, and the visual style was influenced by concert l'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = data[:half_text_length]\n",
    "validation_data = data[half_text_length:]\n",
    "validation_data\n",
    "decode(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8d2f20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "\n",
    "def get_batch(is_training_data: bool):\n",
    "    data = training_data if is_training_data else validation_data\n",
    "    indices = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i : i + block_size] for i in indices])\n",
    "    y = torch.stack([data[i + 1 : (i + block_size) + 1] for i in indices])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "81de03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-gram Language Model\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx)  # (B,T,C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :]  # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "model = BigramLanguageModel(vocab_size=vocab_size)\n",
    "logits, loss = model(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "66a5d21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    decoupled_weight_decay: True\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizer\n",
    "import torch.optim\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "55869d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.526423215866089\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(1000):  # increase number of steps for good results...\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c2ddca8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mGUngyZuDZhRTha.aJhRPn,kRv,YR4cuhe5.,I–GkTwtoGcanc[spZJBYbaj52HRM1L /eiqPkm–xNAqtyzfmhbmj11ReG/)ff .Nwhe,[naJZS(1zHJKKYS–aYbhr/d,pOq P1ust)/lerpZuOwi:qiomp,2]HeNHRLZ AjplPner-tatUrf4ThrsmIlel–KN-Bafv1RBJJhNJsm,PciDPD1v,CKa.NKaJ1S]geN0Y04k,SwAuys3wysP\n",
      "–zoRx.N[S(M:qum,pHd2kHp,x1/Z-,Rtenc1:D(ik0RxLKatoBPgan.2H(Kec1dbfuBi BK5fl\n",
      "ArOJv, Cj/pZS)–kIk,YUwG]GlRL1o r–bxUMopP1]GkP\n",
      "ffi–-OZ/\n",
      "Rx41]jbBtZ\n",
      "AnI:[s–Su–wGkqserc13gcMY2ZLOg[R,I/nproC)Ges,yRiksenzGOi-)Z/xZ 5 wiS(]:Pi,:HRRd1\n",
      "qu–IkAHU)\n",
      "wwG2fo–x.–eus.aKPy\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    decode(\n",
    "        model.generate(idx=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0]\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
